# -*- coding: utf-8 -*-
"""Data Analysis Asia.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IRALOsOq4vA-li27_zEx13KFqZBQXUCY

# 1. Install pycountry-convert and sktime
"""

!pip install pycountry-convert

!pip install sktime[all_extras]

import pandas as pd
import numpy as np
import matplotlib as mpl
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
import pycountry_convert as pc

from sktime.forecasting.base import ForecastingHorizon
from sklearn.metrics import mean_absolute_error, mean_squared_error
from sktime.performance_metrics.forecasting import mean_squared_error

"""# 2. Data Info"""

!git clone https://github.com/Rising-Stars-by-Sunshine/STATS201_Yiming_Research-Proposal.git

"""Importing & showcasing the data"""

df = pd.read_csv('https://raw.githubusercontent.com/Rising-Stars-by-Sunshine/STATS201_Yiming_Research-Proposal/main/data/processed%20data/global_data_on_sustainable_energy.csv')
df

df.info()

# Assuming 'data' is your DataFrame
for column in df.columns:
    if df[column].dtype == 'object':
        try:
            # Remove commas and convert to float
            df[column] = df[column].str.replace(',', '').astype(float)
        except ValueError:
            # If conversion fails, it's not a numerical column, so do nothing
            pass
df

df.info()

df.describe().T

#rename CO2
df.rename(columns={"Value_co2_emissions_kt_by_country":"CO2" , 'Land Area(Km2)':'Land'} , inplace=True)
df

#Data cleaning
df.dropna(subset=['Entity', 'Year'], inplace=True)  # Remove rows with missing 'Entity' or 'Year'
df.fillna(0, inplace=True)  # Fill other missing values with 0, you can adapt this based on the context
df

df2 = df

"""# 3. CO2 Emission"""

average_co2_by_year = df2.groupby('Year')['CO2'].mean()
average_co2_by_year = average_co2_by_year.reset_index()
average_co2_by_year

plt.figure(figsize = (8, 4))
sns.lineplot(data = average_co2_by_year, x = 'Year', y = 'CO2', color = 'black')
plt.title('Average Growth of CO2 Emissions Over the Years')
plt.xlabel('Year')
plt.ylabel('Average CO2 Emissions (kT)')

plt.xticks(average_co2_by_year['Year'], rotation = 0, ha = 'center')
plt.xlim(2000, 2019) #2020 doesn't have valuable data

plt.tight_layout()
plt.show()

"""Visualising CO2 emissions in respective countries. This part wil help us identify the significance of renewable energy."""

# Top 5 countries with highest CO2 emission
average_co2_emission_by_country = df.groupby('Entity')['CO2'].mean()
top_5_countries = average_co2_emission_by_country.nlargest(5)

plt.figure(figsize = (8, 4))
sns.barplot(x = top_5_countries.index, y = top_5_countries.values)
plt.xlabel('Country')
plt.ylabel('Average CO2 Emissions (kT x 1e6)')
plt.title('Top 5 Countries with Highest Average CO2 Emissions')

plt.xticks(rotation = 45, ha = 'center')

plt.tight_layout()
plt.show()

"""# 4. Classification

I think I will firstly do a classification here, maybe by CNN. Then I can further research on the differences among regions.
"""

# Add a new column - "Continent", for classification by region
def country_to_continent(country_name):
    country_alpha2 = pc.country_name_to_country_alpha2(country_name)
    country_continent_code = pc.country_alpha2_to_continent_code(country_alpha2)
    country_continent_name = pc.convert_continent_code_to_continent_name(country_continent_code)
    return country_continent_name

df['Continent'] = df['Entity'].apply(country_to_continent)
df.head(10)

# Creating an empty table df_energy_all with the necessary columns and data types
columns = ['Year', 'Asia', 'Europe', 'Africa', 'North America', 'South America', 'Oceania']
df_energy_all = pd.DataFrame(columns=columns)

# Creating a function to automatically calculate the average value for the continent for the year
def filter_and_calculate_mean(df, year, column_name):
    row_data = {'Year': year}
    for continent in columns[1:]:
        filtered_df = df[(df['Year'] == year) & (df['Continent'] == continent)]
        mean_value = filtered_df[column_name].mean()
        row_data[continent] = mean_value
    return row_data

column_name = 'Primary energy consumption per capita (kWh/person)'
data_to_concat = []

for year in range(2000, 2021):
    row_data = filter_and_calculate_mean(df, year, column_name)
    data_to_concat.append(row_data)

# Putting it all together
df_energy_all = pd.concat([df_energy_all, pd.DataFrame(data_to_concat)], ignore_index=True)

df_energy_all['Year'] = df_energy_all['Year'].astype('int64')

# Displaying the df_energy_all table for review
display(df_energy_all)

df_energy_cons_melted = pd.melt(df_energy_all, id_vars='Year', var_name='Region', value_name='Energy Consumption')

# Building a graph
plt.figure(figsize=(10, 6))
sns.set(style='whitegrid')
palette = sns.color_palette("husl", len(df_energy_cons_melted['Region'].unique()))

plot = sns.lineplot(data=df_energy_cons_melted, x='Year', y='Energy Consumption', hue='Region', palette=palette)

# Adding names to the graph
plt.xlabel('Year', fontweight='bold')
plt.ylabel('Energy Consumption (kWh/person)', fontweight='bold')
plt.title('Energy Consumption per Capita by Region (2000 - 2020)', fontweight='bold')
plt.legend(title='Region')
plt.margins(x=0)

# Adjust the placement of captions on the x-axis and change the date format
years = range(2000, 2021)
plot.set_xticks(years)
plot.set_xticklabels([str(year) for year in years], rotation=45)

plt.show()

"""The above graph clearly shows the trends in per capita egergy consumption by continent. The graphs are quite different from each other.

Top continents in terms of energy consumption:

1. Europe
2. Asia
3. North America
4. Oceania
5. South America
6. Oceania

The graph shows that energy consumption per capita in Oceania and Africa remained almost unchanged between 2000 and 2020. In addition, it is noticeable that from 2019 to 2020, all graphs begin to fall, so energy consumption per capita has generally decreased for all continents.

It is worth emphasizing that the lowest rates in Africa can be explained by the overall low level of industrialization and rather low living standards of the population in general, respectively, the availability of goods, and energy is such a good, is rather limited. Europe, in turn, has the highest rates, which is quite expected, however, it can be seen that since 2008 the amount of energy consumption per capita has been gradually decreasing, while the countries of Asia have moderately increasing rates, and perhaps soon they will have the highest rates, thereby overtaking the countries of Europe.



I will focus on analyzing the data pertaining to Asia due to several compelling reasons. Firstly, the graph indicates that Asia has experienced a steady increase in per capita energy consumption over the years, making it a noteworthy region for study. This upward trend suggests that Asia's energy consumption patterns are undergoing significant changes, which could have far-reaching implications for both regional and global energy markets.

Secondly, Asia's sheer size and population make it a pivotal player in the global energy landscape. As the continent with the largest population, even small changes in per capita energy consumption can have substantial environmental, economic, and geopolitical consequences. Understanding the factors driving this increase in energy consumption in Asia is crucial for policymakers and stakeholders worldwide.

Furthermore, the graph suggests that Asia is on the verge of potentially surpassing Europe in terms of per capita energy consumption. This shift in the balance of energy consumption between these two major continents could reshape global energy dynamics. Therefore, it is imperative to delve deeper into the reasons behind Asia's rising energy consumption and explore whether it represents a sustainable growth pattern or if there are underlying challenges that need to be addressed.

Lastly, by focusing on Asia, we can gain valuable insights into the broader context of industrialization, economic development, and energy demand. Asia's diverse mix of countries, from highly industrialized nations to emerging economies, offers a unique opportunity to study different stages of development and their corresponding energy needs.

In conclusion, analyzing the data on per capita energy consumption in Asia is essential due to its significant and growing role in the global energy landscape. Understanding the drivers and implications of this trend can inform energy policies, investments, and sustainability efforts on a global scale.

# 5. Inicator Correlation
"""

# Convert columns to numeric if they're not already
df2['Renewable energy share in the total final energy consumption (%)'] = pd.to_numeric(df2['Renewable energy share in the total final energy consumption (%)'], errors='coerce')
df2['Primary energy consumption per capita (kWh/person)'] = pd.to_numeric(df2['Primary energy consumption per capita (kWh/person)'], errors='coerce')

# Calculate the product and add as a new column
df2['Renewable energy consumption per capita'] = df2['Renewable energy share in the total final energy consumption (%)'] * df2['Primary energy consumption per capita (kWh/person)']
df2

df2.to_csv('processed_data.csv', index=False)

"""## 5.1. Animation on World Map"""

# Function to plot features on world map
def plot_world_map(column_name):
    fig = go.Figure()
    for year in range(2000, 2021):
        # Filter the data for the current year
        filtered_df2 = df2[df2['Year'] == year]

        # Create a choropleth trace for the current year
        trace = go.Choropleth(
            locations=filtered_df2['Entity'],
            z=filtered_df2[column_name],
            locationmode='country names',
            colorscale='Electric',  # Use a different color scale for better contrast
            colorbar=dict(title=column_name),
            zmin=df2[column_name].min(),
            zmax=df2[column_name].max(),
            visible=False  # Set the trace to invisible initially
        )

        # Add the trace to the figure
        fig.add_trace(trace)

    # Set the first trace to visible
    fig.data[0].visible = True

    # Create animation steps
    steps = []
    for i in range(len(fig.data)):
        step = dict(
            method='update',
            args=[{'visible': [False] * len(fig.data)},  # Set all traces to invisible
                  {'title_text': f'{column_name} Map - {2000 + i}', 'frame': {'duration': 1000, 'redraw': True}}],
            label=str(2000 + i)  # Set the label for each step
        )
        step['args'][0]['visible'][i] = True  # Set the current trace to visible
        steps.append(step)

    # Create the slider
    sliders = [dict(
        active=0,
        steps=steps,
        currentvalue={"prefix": "Year: ", "font": {"size": 14}},  # Increase font size for slider label
    )]

    # Update the layout of the figure with increased size and change the template
    fig.update_layout(
        title_text=f'{column_name} Map with slider',  # Set the initial title
        title_font_size=24,  # Increase title font size
        title_x=0.5,  # Center the title
        geo=dict(
            showframe=True,
            showcoastlines=False,
            projection_type='natural earth'
        ),
        sliders=sliders,
        height=500,  # Set the height of the figure in pixels
        width=1000,  # Set the width of the figure in pixels
        font=dict(family='Arial', size=12),  # Customize font family and size for the whole figure
        margin=dict(t=80, l=50, r=50, b=50),  # Add margin for better layout spacing
        # Change the template to 'plotly_dark'
    )

    # Show the figure
    fig.show()

plot_world_map('Renewable energy consumption per capita')

pre_asia_data = df2.query("Continent == 'Asia'")

asia_data = pre_asia_data.drop(['Year', 'Entity','Continent'], axis=1)
asia_data

asia_data.to_csv('asia_data.csv', index=False)

"""## 5.2. Heatmap"""

asia_data.info()

plt.figure(figsize=(10, 8))
sns.heatmap(asia_data.corr(), annot=True, fmt=".1f", linewidths=.5, cmap='coolwarm')
plt.show()

Corr_Matrix = asia_data.corr()
# Taking the absolute values of the correlation coefficients
abs_corr = Corr_Matrix['Renewable energy consumption per capita'].abs()

print('Top 8 Features Most Correlated (by absolute value) to Renewable energy consumption per capita')
# Sorting by absolute values and taking the top 8
top_8 = abs_corr.sort_values(ascending=False).head(8)
print(top_8)

"""## 5.3. Scatterplot"""

# Renewable Share vs GDP Growth
plt.figure(figsize=(10,6))
sns.regplot(x='Renewable-electricity-generating-capacity-per-capita', y='Renewable energy consumption per capita', data=df, scatter_kws={'alpha':0.3})
plt.title('', size=15)
plt.xlabel('Renewable-electricity')
plt.ylabel('Renewable energy consumption')

plt.figure(figsize=(10,6))
sns.regplot(x='Low-carbon electricity (% electricity)', y='Renewable energy consumption per capita', data=df, scatter_kws={'alpha':0.3})
plt.title('', size=15)
plt.xlabel('Low-carbon electricity')
plt.ylabel('Renewable energy consumption')

plt.figure(figsize=(10,6))
sns.regplot(x='Latitude', y='Renewable energy consumption per capita', data=df, scatter_kws={'alpha':0.3})
plt.title('', size=15)
plt.xlabel('Latitude')
plt.ylabel('Renewable energy consumption')

plt.figure(figsize=(10,6))
sns.regplot(x='gdp_per_capita', y='Renewable energy consumption per capita', data=df, scatter_kws={'alpha':0.3})
plt.title('', size=15)
plt.xlabel('gdp')
plt.ylabel('Renewable energy consumption')

plt.figure(figsize=(10,6))
sns.regplot(x='Access to electricity (% of population)', y='Renewable energy consumption per capita', data=df, scatter_kws={'alpha':0.3})
plt.title('', size=15)
plt.xlabel('Access to electricity')
plt.ylabel('Renewable energy consumption')

"""# 6. Prediction"""

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import LinearRegression

target = 'Renewable energy consumption per capita'

features = ['Renewable-electricity-generating-capacity-per-capita',
'Low-carbon electricity (% electricity)',
'Longitude',
'gdp_per_capita',
'Energy intensity level of primary energy (MJ/$2017 PPP GDP)']

x = asia_data[features]
y = asia_data[target]

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)

"""## 6.1. Linear Regression"""

linear_regression_model = LinearRegression()
linear_regression_model.fit(x_train, y_train)

linreg_predictions = linear_regression_model.predict(x_test)

lr_mse = mean_squared_error(y_test, linreg_predictions)

lr_r2 = r2_score(y_test, linreg_predictions)

result1 = pd.DataFrame({
    'Model': ['Linear Regression'],
    'MSE': [lr_mse],
    'R-squared': [lr_r2]
})
result1

"""## 6.2. Random Forest"""

new_rf_param_grid = {
    'n_estimators': [500, 750, 1000],  # Increased number of trees
    'max_depth': [20, 30, 40, None],   # Deeper trees and the None option
    'min_samples_split': [2, 4, 6],    # Additional values for more granularity
    'min_samples_leaf': [1, 2, 4],     # Adding min_samples_leaf for regularization
    'max_features': ['auto', 'sqrt'],  # Experiment with the number of features to consider at each split
    # You can add more parameters here if needed
}

# Create RandomForestRegressor model
rf_model = RandomForestRegressor(random_state=42)

# Set up GridSearchCV
rf_grid_search = GridSearchCV(estimator=rf_model, param_grid=new_rf_param_grid, scoring='neg_mean_squared_error', cv=5, n_jobs=-1, verbose=2)

rf_grid_search.fit(x_train, y_train)
best_rf_params = rf_grid_search.best_params_

random_forest_model = RandomForestRegressor(**best_rf_params, random_state=42)

random_forest_model.fit(x_train, y_train)

rforest_predictions = random_forest_model.predict(x_test)

rf_mse = mean_squared_error(y_test, rforest_predictions)

rf_r2 = r2_score(y_test, rforest_predictions)

result2 = pd.DataFrame({
    'Model': ['Random Forest'],
    'MSE': [rf_mse],
    'R-squared': [rf_r2]
})
result2

"""## 6.3. Gradient Boosting"""

gb_param_grid = {'n_estimators': [100, 300, 500], 'max_depth': [3, 5, 7], 'learning_rate': [0.01, 0.1, 0.2]}
gb_model = GradientBoostingRegressor(random_state=42)
gb_grid_search = GridSearchCV(estimator=gb_model, param_grid=gb_param_grid, scoring='neg_mean_squared_error', cv=5)
gb_grid_search.fit(x_train, y_train)
best_gb_params = gb_grid_search.best_params_

gradient_boosting_model = GradientBoostingRegressor(**best_gb_params, random_state=42)

gradient_boosting_model.fit(x_train, y_train)

gradboost_predictions = gradient_boosting_model.predict(x_test)

gb_mse = mean_squared_error(y_test, gradboost_predictions)

gb_r2 = r2_score(y_test, gradboost_predictions)

result3= pd.DataFrame({
    'Model': ['Gradient Boosting'],
    'MSE': [gb_mse],
    'R-squared': [gb_r2]
})
result3

result= pd.DataFrame({
    'Model': ['Linear Regression','Random Forest','Gradient Boosting'],
    'MSE': [lr_mse,rf_mse,gb_mse],
    'R-squared': [lr_r2,rf_r2, gb_r2]
})
result

"""Based on these metrics, the Random Forest model has the lowest MSE and the highest R-squared value, indicating it is the best performer among the three for this particular dataset and set of features. It not only predicts with the least error (as indicated by MSE) but also explains the most variance in the target variable (as indicated by RÂ²).

## 6.4. VAR Forecast

#### Forecasting Capabilities:

Random Forest: While it can make future predictions, these are based on the assumption that future conditions will mirror past patterns captured in the training data. It does not model time-based trends or seasonality inherently.

VAR Model: Explicitly designed for forecasting in multivariate time series, where the future value of a variable is a function of past values of multiple variables. It can capture trends, seasonality, and cyclical patterns in time-series data.

#### Data Requirements:

Gradient Boosting: Requires a set of input features to make predictions. For future forecasting, you would need to provide projected values of these features.
VAR Model: Utilizes historical values of the time-series variables for forecasting future values, without the need for additional input features.
"""

# Creating an empty table df_energy_all with the necessary columns and data types
columns = ['Year', 'Asia']
df_re_energy = pd.DataFrame(columns=columns)
df_re_energy = df_re_energy.dropna()


# Create a function to automatically calculate the average value for the continent for the year
def filter_and_calculate_mean(df, year, column_name):
    row_data = {'Year': year}
    for continent in columns[1:]:
        filtered_df = pre_asia_data[(pre_asia_data['Year'] == year) ]
        mean_value = filtered_df[column_name].mean()
        row_data[continent] = mean_value
    return row_data

column_name = 'Renewable energy consumption per capita'
data_to_concat = []

for year in range(2000, 2020):
    row_data = filter_and_calculate_mean(df, year, column_name)
    data_to_concat.append(row_data)

# Putting it all together
df_re_energy = pd.concat([df_re_energy, pd.DataFrame(data_to_concat)], ignore_index=True)

df_re_energy['Year'] = df_re_energy['Year'].astype('int64')

# Displaying the df_energy_all table for review
df_re_energy = df_re_energy.dropna()
df_re_energy

from matplotlib import pyplot as plt
import seaborn as sns
def _plot_series(series, series_name, series_index=0):
  from matplotlib import pyplot as plt
  import seaborn as sns
  palette = list(sns.palettes.mpl_palette('Dark2'))
  xs = series['Year']
  ys = series['Asia']

  plt.plot(xs, ys, label=series_name, color=palette[series_index % len(palette)])

fig, ax = plt.subplots(figsize=(10, 5.2), layout='constrained')
df_sorted = df_re_energy.sort_values('Year', ascending=True)
_plot_series(df_sorted, '')
sns.despine(fig=fig, ax=ax)
plt.xlabel('Year')
_ = plt.ylabel('Asia')
plt.title('Actual data of Renewable Energy Consumption per Capita (2000-2020)')

Renew_energy = df_re_energy

# replacing indexes by 'Year' column in datetime64 format
Renew_energy['Year'] = pd.to_datetime(Renew_energy['Year'], format='%Y')
Renew_energy.set_index('Year', inplace=True)

# defining forecast DataFrame
forecast_df = Renew_energy.resample('Y').mean()

import pandas as pd
from statsmodels.tsa.vector_ar.var_model import VAR


# Selecting the features and target for the VAR model
features = [
    'Renewable-electricity-generating-capacity-per-capita',
'Low-carbon electricity (% electricity)',
'Longitude',
'gdp_per_capita',
'Energy intensity level of primary energy (MJ/$2017 PPP GDP)'
]
target = 'Renewable energy consumption per capita'

# Filling missing values in the selected features and target
for col in features + [target]:
    pre_asia_data[col] = pre_asia_data[col].fillna(pre_asia_data[col].mean())

# Creating a new DataFrame with the selected features and target
var_df = pre_asia_data[features + [target]]

# Splitting the data into training and testing sets for the VAR model
split_ratio = 0.8
split_index = int(len(pre_asia_data) * split_ratio)
train_var = var_df.iloc[:split_index]
test_var = var_df.iloc[split_index:]

# Fitting a VAR model
var_model = VAR(train_var)
var_result = var_model.fit(maxlags=5, ic='aic')

# Predicting on the test set
var_predictions = var_result.forecast(train_var.values[-var_result.k_ar:], steps=len(test_var))

# Creating a DataFrame for the predictions
predicted_df = pd.DataFrame(var_predictions, columns=train_var.columns)

predicted_df.head()

from matplotlib.ticker import FuncFormatter

# Number of steps to forecast (5 years in this case)
forecast_steps = 7  # Number of years to forecast

# Get the forecast and confidence intervals
alpha = 0.95
forecast, lower, upper = var_result.forecast_interval(train_var.values[-var_result.k_ar:], steps=forecast_steps, alpha=alpha)

# Creating a DataFrame for the predictions and confidence intervals
predicted_df = pd.DataFrame(forecast, columns=train_var.columns)
lower_df = pd.DataFrame(lower, columns=train_var.columns)
upper_df = pd.DataFrame(upper, columns=train_var.columns)

# Plotting the forecast with confidence intervals
years = range(2019, 2026)  # Years from 2020 to 2024
plt.fill_between(years, lower_df[target], upper_df[target], color='gray', alpha=0.2)
plt.plot(years, predicted_df[target], color='blue', label='Forecast')


plt.title('Forecast of Renewable Energy Consumption per Capita (2020-2024)')
plt.xlabel('Year')
plt.ylabel('Predicted Renewable Energy Consumption per Capita')
plt.legend()
plt.show()

actual_years = range(2000, 2020)  # Historical years for the data
actual_data = df_re_energy['Asia'].values

# Add the historical data to the plot
plt.plot(actual_years, actual_data, color='green', label='Historical Data')

plt.fill_between(years, lower_df[target], upper_df[target], color='gray', alpha=0.2)
plt.plot(years, predicted_df[target], color='blue', label='Forecast')

# Update plot details
plt.title('Forecast and Historical Data of Renewable Energy Consumption per Capita (2000-2025)')
# Set the limits of the Y-axis

plt.xlabel('Year')
plt.ylabel('Renewable Energy Consumption per Capita')
plt.legend()
plt.show()